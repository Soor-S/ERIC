# squatreading.py
# Build an expert squat profile from a folder of videos (no ML training).
# It extracts reps, computes per-rep features + normalized waveforms,
# and saves profiles/expert_profile_squat.json (means/stds + templates).

import os
import json
import time
import argparse
from pathlib import Path

import cv2
import numpy as np
import mediapipe as mp

# ==============================
# Geometry & small utilities
# ==============================
def angle2d_deg(a, b, c):
    """
    Joint angle at b from points a-b-c in image space (x,y).
    Robust: atan2(|cross|, dot) -> [0, 180] deg. Returns None if degenerate.
    """
    if a is None or b is None or c is None:
        return None
    a = np.asarray(a[:2], dtype=np.float32)
    b = np.asarray(b[:2], dtype=np.float32)
    c = np.asarray(c[:2], dtype=np.float32)
    v1, v2 = a - b, c - b
    n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)
    if n1 < 1e-6 or n2 < 1e-6:
        return None
    dot = float(v1[0] * v2[0] + v1[1] * v2[1])
    cross = float(v1[0] * v2[1] - v1[1] * v2[0])  # 2D scalar cross
    th = float(np.degrees(np.arctan2(abs(cross), dot)))
    return th if 0.0 <= th <= 180.0 else None


def landmark_px(lms, i, w, h):
    return (lms[i].x * w, lms[i].y * h)


def joint_visible_and_valid(lms, triplet, w, h, vis_thresh=0.50, min_len_px=None):
    """
    triplet = (A, B, C) landmark indices.
    All three must exceed visibility threshold and segments be long enough.
    min_len_px defaults to ~8% of the shorter image side (scale-aware).
    """
    A, B, C = triplet
    if not (lms[A].visibility >= vis_thresh and
            lms[B].visibility >= vis_thresh and
            lms[C].visibility >= vis_thresh):
        return False, None, None, None

    a = landmark_px(lms, A, w, h)
    b = landmark_px(lms, B, w, h)
    c = landmark_px(lms, C, w, h)

    len1 = float(np.hypot(a[0] - b[0], a[1] - b[1]))  # AB
    len2 = float(np.hypot(c[0] - b[0], c[1] - b[1]))  # CB
    if min_len_px is None:
        min_len_px = 0.08 * min(w, h)  # ~8% of frame
    if len1 < min_len_px or len2 < min_len_px:
        return False, None, None, None

    return True, a, b, c


def resample_series_ts(ts_x_pairs, T=200):
    """
    Phase-normalize a time series (t, x) to s in [0,1] and resample to length T.
    Returns list length T.
    """
    if not ts_x_pairs or len(ts_x_pairs) < 3:
        return [0.0] * T
    ts = np.asarray([p[0] for p in ts_x_pairs], dtype=np.float32)
    xs = np.asarray([p[1] for p in ts_x_pairs], dtype=np.float32)
    t0, t1 = ts[0], ts[-1]
    if t1 <= t0 + 1e-6:
        return [float(xs[-1])] * T
    s = (ts - t0) / (t1 - t0)
    s_new = np.linspace(0.0, 1.0, T, dtype=np.float32)
    x_new = np.interp(s_new, s, xs)
    return x_new.tolist()


def closest_value(series, t_ref):
    if not series or t_ref is None:
        return None
    return min(series, key=lambda p: abs(p[0] - t_ref))[1]


# ==============================
# Per-frame angles for squat
# ==============================
def compute_angles_frame(lms, w, h):
    """
    Returns per-frame angles:
      knee_L/R, hip_L/R (proxy), trunk, pelvis_tilt, valgus_L/R, ankle_L/R
    """
    out = {}
    if lms is None:
        return out

    L_SH, L_EL, L_WR = 11, 13, 15
    R_SH, R_EL, R_WR = 12, 14, 16
    L_HP, L_KN, L_AN = 23, 25, 27
    R_HP, R_KN, R_AN = 24, 26, 28
    L_TOE, R_TOE = 31, 32

    def px(i): return landmark_px(lms, i, w, h)

    # Knees: (hip-knee-ankle)
    for side, hp, kn, an in (("L", L_HP, L_KN, L_AN), ("R", R_HP, R_KN, R_AN)):
        ok, a, b, c = joint_visible_and_valid(lms, (hp, kn, an), w, h, 0.50)
        out[f"knee_{side}"] = angle2d_deg(a, b, c) if ok else None

    # Hips (proxy): (shoulder-hip-knee)
    for side, sh, hp, kn in (("L", L_SH, L_HP, L_KN), ("R", R_SH, R_HP, R_KN)):
        ok, a, b, c = joint_visible_and_valid(lms, (sh, hp, kn), w, h, 0.50)
        out[f"hip_{side}"] = angle2d_deg(a, b, c) if ok else None

    # Trunk vs vertical: vector mid-hip -> mid-shoulders; angle from vertical
    try:
        lh, rh = px(L_HP), px(R_HP)
        ls, rs = px(L_SH), px(R_SH)
        mid_hip = ((lh[0] + rh[0]) / 2.0, (lh[1] + rh[1]) / 2.0)
        mid_sh = ((ls[0] + rs[0]) / 2.0, (ls[1] + rs[1]) / 2.0)
        v = (mid_sh[0] - mid_hip[0], mid_sh[1] - mid_hip[1])
        out["trunk"] = float(np.degrees(np.arctan2(abs(v[0]), abs(v[1]) + 1e-9)))
    except Exception:
        out["trunk"] = None

    # Pelvis tilt: angle of hip line vs horizontal
    try:
        lh, rh = px(L_HP), px(R_HP)
        dx, dy = rh[0] - lh[0], rh[1] - lh[1]
        out["pelvis_tilt"] = float(np.degrees(np.arctan2(abs(dy), abs(dx) + 1e-9)))
    except Exception:
        out["pelvis_tilt"] = None

    # Valgus proxy: 180 - angle(hip-knee-ankle) (larger => more "cave")
    def valgus(h, k, a):
        try:
            v1 = np.array([k[0] - h[0], k[1] - h[1]], dtype=np.float32)
            v2 = np.array([a[0] - k[0], a[1] - k[1]], dtype=np.float32)
            n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)
            if n1 < 1e-6 or n2 < 1e-6:
                return None
            th = np.degrees(np.arccos(np.clip(np.dot(v1, v2) / (n1 * n2), -1, 1)))
            return 180.0 - th
        except Exception:
            return None

    try:
        out["valgus_L"] = valgus(landmark_px(lms, L_HP, w, h), landmark_px(lms, L_KN, w, h), landmark_px(lms, L_AN, w, h))
        out["valgus_R"] = valgus(landmark_px(lms, R_HP, w, h), landmark_px(lms, R_KN, w, h), landmark_px(lms, R_AN, w, h))
    except Exception:
        out["valgus_L"] = out["valgus_R"] = None

    # Ankle dorsiflexion: (knee-ankle-toe)
    for side, kn, an, toe in (("L", L_KN, L_AN, L_TOE), ("R", R_KN, R_AN, R_TOE)):
        ok, a, b, c = joint_visible_and_valid(lms, (kn, an, toe), w, h, 0.50)
        out[f"ankle_{side}"] = angle2d_deg(a, b, c) if ok else None

    return out


# ==============================
# Per-rep features
# ==============================
def compute_features(rep_slice, t_start, t_bottom, t_end):
    """
    rep_slice: dict name -> [(t,deg)] for signals collected during the rep window
    Returns dict of scalar features for scoring/profile-building.
    """
    feats = {}
    primary = rep_slice["knee"]
    if len(primary) < 3:
        return None

    xs = np.array([x for (_, x) in primary], dtype=np.float32)
    ts = np.array([t for (t, _) in primary], dtype=np.float32)
    feats["rep_duration"] = float(ts[-1] - ts[0])
    feats["min_angle"] = float(xs.min())
    feats["max_angle"] = float(xs.max())
    feats["rom"] = float(xs.max() - xs.min())

    feats["ecc_time"] = float(max(0.0, (t_bottom - t_start))) if (t_bottom and t_start) else None
    feats["con_time"] = float(max(0.0, (t_end - t_bottom))) if (t_bottom and t_end) else None

    # dwell near endpoints (±3°)
    def dwell(series, center, band=3.0):
        tot = 0.0
        inb = False
        last = None
        for (t, x) in series:
            if abs(x - center) <= band:
                if not inb:
                    inb = True
                    last = t
            else:
                if inb:
                    tot += max(0.0, t - (last if last is not None else t))
                    inb = False
        if inb and last is not None:
            tot += series[-1][0] - last
        return float(tot)

    feats["bottom_dwell"] = dwell(primary, feats["min_angle"], 3.0)
    feats["top_dwell"] = dwell(primary, feats["max_angle"], 3.0)

    # stability near endpoints (std in ±120 ms windows)
    def window_std(series, tc, win=0.12):
        xs_win = [x for (t, x) in series if tc is not None and abs(t - tc) <= win]
        return float(np.std(np.asarray(xs_win, dtype=np.float32))) if len(xs_win) >= 2 else None

    feats["std_bottom"] = window_std(primary, t_bottom, 0.12) if t_bottom else None
    feats["std_top"] = window_std(primary, t_end, 0.12) if t_end else None

    # symmetry (mean |knee_L - knee_R|)
    L = rep_slice.get("knee_L", [])
    R = rep_slice.get("knee_R", [])
    asym = None
    if L and R:
        rt = [t for (t, _) in R]
        diffs = []
        import bisect
        for (tL, xL) in L:
            j = bisect.bisect_left(rt, tL)
            cand = []
            if j < len(R):
                cand.append(abs(xL - R[j][1]))
            if j > 0:
                cand.append(abs(xL - R[j - 1][1]))
            if cand:
                diffs.append(min(cand))
        if len(diffs) >= 5:
            asym = float(np.mean(diffs))
    feats["asym_deg"] = asym

    # snapshots at bottom
    for name in ("trunk", "pelvis_tilt", "valgus_L", "valgus_R",
                 "hip_L", "hip_R", "ankle_L", "ankle_R"):
        feats[f"{name}_at_bottom"] = closest_value(rep_slice.get(name, []), t_bottom)

    return feats


# ==============================
# Rep detection (knee-driven)
# ==============================
class RepDetectorSimple:
    """
    Simple knee-angle driven state machine:
    at_top -> moving_down -> moving_up -> back_to_top => rep_complete
    """
    def __init__(self, min_rom=25.0, deadband=0.5, refractory=0.35):
        self.min_rom = float(min_rom)
        self.deadband = float(deadband)
        self.refractory = float(refractory)
        self.prev = None
        self.prev_dir = 0
        self.state = "at_top"
        self.state_t = 0.0
        self.start_t = None
        self.bottom_t = None
        self.end_t = None

    def _dir(self, da):
        if abs(da) <= self.deadband:
            return 0
        return 1 if da > 0 else -1

    def update(self, t, a):
        out = {}
        if a is None:
            return out
        if self.prev is None:
            self.prev = a
            self.state_t = t
            return out

        da = a - self.prev
        cur_dir = self._dir(da)

        if self.state == "at_top" and cur_dir < 0:
            self.start_t = t
            out["rep_start"] = True
            self.state = "moving_down"
            self.state_t = t
        elif self.state == "moving_down" and cur_dir > 0:
            self.bottom_t = t
            out["bottom"] = True
            self.state = "moving_up"
            self.state_t = t
        elif self.state == "moving_up" and cur_dir < 0 and (t - self.state_t) >= self.refractory:
            self.end_t = t
            out["rep_complete"] = True
            self.state = "at_top"
            self.state_t = t

        self.prev = a
        if cur_dir != 0:
            self.prev_dir = cur_dir
        return out


# ==============================
# Frame preprocessing for better landmarks
# ==============================
def preprocess_frame_for_pose(frame_bgr):
    """
    Resize -> mild denoise -> CLAHE on luma -> RGB
    """
    target_w, target_h = 1280, 720
    h0, w0 = frame_bgr.shape[:2]
    scale = min(target_w / w0, target_h / h0)
    if scale < 0.999 or scale > 1.001:
        frame_bgr = cv2.resize(frame_bgr, (int(w0 * scale), int(h0 * scale)), interpolation=cv2.INTER_LINEAR)

    # Mild denoise
    frame_dn = cv2.bilateralFilter(frame_bgr, d=5, sigmaColor=50, sigmaSpace=50)

    # CLAHE on luma
    yuv = cv2.cvtColor(frame_dn, cv2.COLOR_BGR2YUV)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    yuv[:, :, 0] = clahe.apply(yuv[:, :, 0])
    frame_eq = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)

    rgb = cv2.cvtColor(frame_eq, cv2.COLOR_BGR2RGB)
    rgb.flags.writeable = False
    return rgb


# ==============================
# Process a single video -> list of reps (features + waves)
# ==============================
def process_video(path, T_wave=200, verbose=True):
    cap = cv2.VideoCapture(str(path))
    if not cap.isOpened():
        print(f"[WARN] Cannot open: {path}")
        return []

    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=2,
        min_detection_confidence=0.60,
        min_tracking_confidence=0.65
    )

    L_HP, L_KN, L_AN = 23, 25, 27
    R_HP, R_KN, R_AN = 24, 26, 28

    det = RepDetectorSimple(min_rom=25.0, deadband=0.5, refractory=0.35)

    traces = {k: [] for k in ("knee", "knee_L", "knee_R",
                              "hip_L", "hip_R",
                              "trunk", "pelvis_tilt",
                              "valgus_L", "valgus_R",
                              "ankle_L", "ankle_R")}
    per_rep = []

    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    frame_idx = 0
    missing_count = 0  # for re-detect
    while True:
        ok, frame = cap.read()
        if not ok:
            break

        h, w = frame.shape[:2]
        rgb = preprocess_frame_for_pose(frame)

        results = pose.process(rgb)
        lms = results.pose_landmarks.landmark if results.pose_landmarks else None

        if results.pose_landmarks is None:
            missing_count += 1
        else:
            missing_count = 0

        # Re-detect if landmarks missing for a while
        if missing_count >= 10:
            try:
                pose.close()
            except Exception:
                pass
            # Single-frame detection
            pose = mp_pose.Pose(
                static_image_mode=True,
                model_complexity=2,
                min_detection_confidence=0.60,
                min_tracking_confidence=0.65
            )
            _ = pose.process(rgb)
            try:
                pose.close()
            except Exception:
                pass
            # Back to tracking
            pose = mp_pose.Pose(
                static_image_mode=False,
                model_complexity=2,
                min_detection_confidence=0.60,
                min_tracking_confidence=0.65
            )
            missing_count = 0

        # Per-frame angles
        ang = compute_angles_frame(lms, w, h)

        # Primary knee fused
        knee_vals = [ang.get("knee_L"), ang.get("knee_R")]
        knee_vals = [v for v in knee_vals if v is not None]
        knee_fused = float(np.mean(knee_vals)) if knee_vals else None

        # Rep detection (use wall-clock in seconds from frame index)
        t = frame_idx / fps
        ev = det.update(t, knee_fused)

        # Append angles to traces
        if knee_fused is not None:
            traces["knee"].append((t, knee_fused))
        for k in ("knee_L", "knee_R", "hip_L", "hip_R",
                  "trunk", "pelvis_tilt", "valgus_L", "valgus_R",
                  "ankle_L", "ankle_R"):
            v = ang.get(k)
            if v is not None:
                traces[k].append((t, float(v)))

        # On rep complete: slice, compute features, resample waves
        if ev.get("rep_complete", False):
            t0, tb, te = det.start_t, det.bottom_t, det.end_t
            rep_slice = {k: [(tt, xx) for (tt, xx) in traces[k] if t0 <= tt <= te] for k in traces}

            feats = compute_features({
                "knee": rep_slice["knee"],
                "knee_L": rep_slice["knee_L"], "knee_R": rep_slice["knee_R"],
                "trunk": rep_slice["trunk"], "pelvis_tilt": rep_slice["pelvis_tilt"],
                "valgus_L": rep_slice["valgus_L"], "valgus_R": rep_slice["valgus_R"],
                "hip_L": rep_slice["hip_L"], "hip_R": rep_slice["hip_R"],
                "ankle_L": rep_slice["ankle_L"], "ankle_R": rep_slice["ankle_R"]
            }, t0, tb, te)

            if feats:
                knee_wave = resample_series_ts(rep_slice["knee"], T=T_wave)
                trunk_wave = resample_series_ts(rep_slice["trunk"], T=T_wave) if rep_slice["trunk"] else None
                hipL_wave = resample_series_ts(rep_slice["hip_L"], T=T_wave) if rep_slice["hip_L"] else None

                per_rep.append({
                    "features": feats,
                    "waves": {
                        "knee": knee_wave,
                        "trunk": trunk_wave,
                        "hipL": hipL_wave
                    }
                })

            # reset traces for next rep
            traces = {k: [] for k in traces}

        frame_idx += 1

    cap.release()
    if verbose:
        print(f"  -> extracted {len(per_rep)} reps from {Path(path).name}")
    return per_rep


# ==============================
# Build profile from all videos
# ==============================
def build_profile_from_folder(videos_dir, out_json="profiles/expert_profile_squat.json", T_wave=200):
    vids = []
    for ext in ("*.mp4", "*.mov", "*.mkv", "*.avi"):
        vids.extend(list(Path(videos_dir).glob(ext)))
    if not vids:
        print(f"[ERROR] No videos found in: {videos_dir}")
        return

    all_reps = []
    for p in vids:
        print(f"[INFO] Processing: {p.name}")
        reps = process_video(p, T_wave=T_wave, verbose=False)
        print(f"       +{len(reps)} reps")
        all_reps.extend(reps)

    if not all_reps:
        print("[WARN] No reps extracted from any video.")
        return

    # Aggregate scalar features
    scalar_names = [
        "ecc_time", "con_time", "rep_duration",
        "min_angle", "max_angle", "rom",
        "bottom_dwell", "top_dwell",
        "std_bottom", "std_top",
        "asym_deg",
        "trunk_at_bottom", "pelvis_tilt_at_bottom",
        "valgus_L_at_bottom", "valgus_R_at_bottom",
        "hip_L_at_bottom", "hip_R_at_bottom",
        "ankle_L_at_bottom", "ankle_R_at_bottom"
    ]
    scalars = {k: [] for k in scalar_names}
    waves_knee, waves_trunk, waves_hipL = [], [], []

    for r in all_reps:
        f = r["features"]
        for k in scalar_names:
            v = f.get(k, None)
            if v is not None:
                scalars[k].append(float(v))
        if r["waves"].get("knee"):  waves_knee.append(np.array(r["waves"]["knee"], dtype=np.float32))
        if r["waves"].get("trunk"): waves_trunk.append(np.array(r["waves"]["trunk"], dtype=np.float32))
        if r["waves"].get("hipL"):  waves_hipL.append(np.array(r["waves"]["hipL"], dtype=np.float32))

    def fit_stats(vec):
        arr = np.asarray(vec, dtype=np.float32)
        if arr.size == 0:
            return None
        return {"mu": float(np.mean(arr)), "sigma": float(np.std(arr) + 1e-6)}

    feature_stats = {}
    for k, vals in scalars.items():
        st = fit_stats(vals)
        if st:
            feature_stats[k] = st

    def mean_std_stack(stk):
        if not stk:
            return None
        X = np.stack(stk, axis=0)  # N x T
        mu = np.mean(X, axis=0)
        sd = np.std(X, axis=0) + 1e-6
        return {"T": int(X.shape[1]), "mean": mu.tolist(), "std": sd.tolist()}

    templates = {
        "knee":  mean_std_stack(waves_knee),
        "trunk": mean_std_stack(waves_trunk),
        "hipL":  mean_std_stack(waves_hipL)
    }

    prof = {
        "exercise": "squat",
        "version": time.strftime("%Y-%m-%d"),
        "features": feature_stats,
        "templates": templates,
        # Initial exercise-aware weights (tune later if you like)
        "weights": {
            "posture": 0.40,
            "depth_rom": 0.30,
            "control_tempo": 0.15,
            "symmetry": 0.05,
            "shape": 0.10
        },
        # Severity curve for z-score → penalty mapping
        "severity_cut": {"mild": 0.8, "moderate": 1.5, "severe": 2.5}
    }

    Path(out_json).parent.mkdir(parents=True, exist_ok=True)
    with open(out_json, "w") as f:
        json.dump(prof, f, indent=2)
    print(f"[OK] Saved profile to: {out_json}")


# ==============================
# CLI
# ==============================
def main():
    ap = argparse.ArgumentParser(description="Build expert squat profile from videos")
    ap.add_argument("--videos_dir", required=True, help="Folder with expert squat videos (mp4/mov/mkv/avi)")
    ap.add_argument("--out", default="profiles/expert_profile_squat.json", help="Output profile JSON path")
    ap.add_argument("--T", type=int, default=200, help="Waveform resample length")
    args = ap.parse_args()

    build_profile_from_folder(args.videos_dir, out_json=args.out, T_wave=args.T)


if __name__ == "__main__":
    main()
